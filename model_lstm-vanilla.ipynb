{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "tr = pickle.load(open('Dataset/tr.pkl', 'rb'))\n",
    "vl = pickle.load(open('Dataset/vl.pkl', 'rb'))\n",
    "ts = pickle.load(open('Dataset/ts.pkl', 'rb'))\n",
    "\n",
    "print(len(tr), len(vl), len(ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "\n",
    "NLP = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN_MAX = 404\n",
    "\n",
    "class DS_Imdb(Dataset):\n",
    "    def __init__(self, dat):\n",
    "        self.dat = dat\n",
    "        self.END = NLP('ã€‚')[0].vector\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dat)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sent, lbl  = self.dat[idx]\n",
    "        l = len(sent)\n",
    "        \n",
    "        inp = np.zeros((LEN_MAX, 300))\n",
    "        for i in range(l):\n",
    "            inp[i] = sent[i].vector\n",
    "        for i in range(l, LEN_MAX):\n",
    "            inp[i] = self.END\n",
    "        \n",
    "        return l, inp, lbl\n",
    "\n",
    "ld_tr = DataLoader(DS_Imdb(tr), batch_size=32, shuffle=True)\n",
    "ld_vl = DataLoader(DS_Imdb(vl), batch_size=64)\n",
    "ld_ts = DataLoader(DS_Imdb(ts), batch_size=64)\n",
    "\n",
    "for l, inp, ans in ld_tr:\n",
    "    print(l.shape, inp.shape, ans.shape)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_LSTM(nn.Module):\n",
    "    def __init__(self, hid_size=256, mode='vanilla'):\n",
    "        super(Model_LSTM, self).__init__()\n",
    "        \n",
    "        self.hid_size = hid_size\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.lstm = nn.LSTM(300, self.hid_size, num_layers=2, \n",
    "                            batch_first=True, dropout=0.2)\n",
    "        self.fc = nn.Sequential(*[nn.Linear(self.hid_size, 100), nn.ReLU(), nn.Dropout(0.25), \n",
    "                                  nn.Linear(100, 2)]) \n",
    "    \n",
    "    def forward(self, l, inp):\n",
    "        l = l.numpy()\n",
    "        batch_size = inp.shape[0]\n",
    "        \n",
    "        outs = []\n",
    "        for i in range(batch_size):\n",
    "            out, _ = self.lstm(inp[i:i+1, :l[i]])\n",
    "            out = out[:, -1]\n",
    "            \n",
    "            outs.append(out)\n",
    "        out = T.cat(outs, dim=0)\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "model = Model_LSTM().cuda()\n",
    "\n",
    "out = model(l, inp.float().cuda())\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss().cuda()\n",
    "optim = T.optim.Adam(model.parameters(), lr=0.0008)\n",
    "\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStop:\n",
    "    def __init__(self, threshold=10):\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.acc_max = 0\n",
    "        self.cnt = 0\n",
    "\n",
    "    def add(self, acc):\n",
    "        if acc<self.acc_max:\n",
    "            self.cnt += 1\n",
    "        else:\n",
    "            self.cnt = 0\n",
    "            self.acc_max = acc\n",
    "\n",
    "        if self.cnt>=self.threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "ES = EarlyStop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in tqdm(range(EPOCHS)):\n",
    "    ls_ep = 0\n",
    "    \n",
    "    model.train()\n",
    "    with tqdm(ld_tr) as TQ:\n",
    "        for l, inp, ans in TQ:\n",
    "            out = model(l, inp.float().cuda())\n",
    "            ls_bh = loss_func(out, ans.cuda())\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            ls_bh.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            ls_bh = ls_bh.cpu().detach().numpy()\n",
    "            TQ.set_postfix(ls_bh='%.3f'%(ls_bh))\n",
    "            ls_ep += ls_bh\n",
    "        \n",
    "        ls_ep /= len(TQ)\n",
    "        print('Ep %d: %.4f' % (e+1, ls_ep))\n",
    "        \n",
    "        T.save(model.state_dict(), 'Model/lstm-vanilla_%d.pt' % (e+1))\n",
    "        \n",
    "    acc_ep = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with tqdm(ld_vl) as TQ:\n",
    "        for l, inp, ans in TQ:\n",
    "            out = model(l, inp.float().cuda())\n",
    "            \n",
    "            out = out.cpu().detach().numpy()\n",
    "            out = np.argmax(out, axis=1)\n",
    "            ans = ans.numpy()\n",
    "            \n",
    "            acc_bh = np.average(out==ans)\n",
    "            TQ.set_postfix(acc_bh='%.3f'%(acc_bh))\n",
    "            acc_ep += acc_bh\n",
    "        \n",
    "        acc_ep /= len(TQ)\n",
    "        print('%.4f'%(acc_ep))\n",
    "    \n",
    "    if ES.add(acc_ep)==True:\n",
    "        print('Finish training in ep=%d'%(e+1))\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(T.load('Model/lstm-vanilla.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_ep = 0\n",
    "\n",
    "model.eval()\n",
    "with tqdm(ld_ts) as TQ:\n",
    "    for l, inp, ans in TQ:\n",
    "        out = model(l, inp.float().cuda())\n",
    "            \n",
    "        out = out.cpu().detach().numpy()\n",
    "        out = np.argmax(out, axis=1)\n",
    "        ans = ans.numpy()\n",
    "            \n",
    "        acc_bh = np.average(out==ans)\n",
    "        TQ.set_postfix(acc_bh='%.3f'%(acc_bh))\n",
    "        acc_ep += acc_bh\n",
    "        \n",
    "    acc_ep /= len(TQ)\n",
    "    print('%.4f'%(acc_ep))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
